/**
 * ragService.ts
 * -------------------------------------
 * Retrieval-Augmented Generation Service
 * Hybrid Search + Re-Ranking + Cache
 * -------------------------------------
 */
import { InferenceClient } from "@huggingface/inference";
import {
  searchByKeywords,
  searchByVector,
  checkVectorDimension,
  getAiRoles,
  getModels,
} from "./supabaseService.js";
import { reRankResults } from "./reRanker.js";
import { ragCache, embeddingCache } from "./cacheService.js";

export interface KnowledgeChunk {
  id: string;
  content: string;
  metadata: any;
  similarity: number;
  source: "vector" | "keyword" | "hybrid";
}

export class RAGService {
  private readonly CACHE_TTL = 300_000; // 5 minutes
  private hfClient: InferenceClient;
  private vectorWeight: number = 0.7;
  private keywordWeight: number = 0.3;
  private minSimilarity: number = 0.3;

  constructor(hfClient: InferenceClient) {
    this.hfClient = hfClient;
    // Initialize with default values, will be updated when needed
    this.loadConfig();
  }

  private async loadConfig() {
    try {
      const { getRagConfig } = await import('./supabaseService.js');
      const config = await getRagConfig();
      this.vectorWeight = config.vectorWeight;
      this.keywordWeight = config.keywordWeight;
      this.minSimilarity = config.minSimilarity;
    } catch (error) {
      console.error("[RAG] Error loading configuration, using defaults:", error);
      // Keep default values if config loading fails
    }
  }

  /**
   * Enhanced Hybrid Search: semantic + keyword with Vietnamese administrative term handling
   */
  async searchKnowledge(
    query: string,
    topK: number = 5,
  ): Promise<KnowledgeChunk[]> {
    console.log(`\n[RAG] üîç Search query: "${query}"`);
    if (!query?.trim()) {
      console.warn("[RAG] ‚ö†Ô∏è Empty query received.");
      return [];
    }

    // Reload configuration to ensure we have the latest values
    await this.loadConfig();

    const cacheKey = ragCache.getCacheKey("rag", { query, topK });
    const cached = ragCache.get<KnowledgeChunk[]>(cacheKey);
    if (cached) {
      console.log("[RAG] ‚úÖ Cache hit.");
      return cached;
    }

    const start = Date.now();
    try {
      // Check dimension integrity
      const dim = await checkVectorDimension(
        "knowledge_chunks",
        "embedding",
      );
      if (dim && dim !== 384)
        console.warn(
          `[RAG] ‚ö†Ô∏è Vector dimension mismatch (DB=${dim}, expected=384)`,
        );

      // Enhanced query processing for Vietnamese administrative terms
      const enhancedQuery = this.enhanceQueryForVietnameseTerms(query);

      // Perform hybrid search
      const [vectorResults, keywordResults] = await Promise.allSettled([
        this.searchByVector(enhancedQuery, topK * 2),
        this.searchByKeywords(enhancedQuery, topK * 2),
      ]);

      const safeVector =
        vectorResults.status === "fulfilled" ? vectorResults.value : [];
      const safeKeyword =
        keywordResults.status === "fulfilled" ? keywordResults.value : [];

      const merged = this.mergeAndRank(safeVector, safeKeyword, topK);

      // Optional Re-ranking
      const ranked = await reRankResults(this.hfClient, enhancedQuery, merged);

      ragCache.set(cacheKey, ranked, this.CACHE_TTL);
      const ms = Date.now() - start;
      console.log(
        `[RAG] ‚úÖ Completed hybrid search (${ranked.length} results in ${ms}ms)`,
      );

      return ranked;
    } catch (err) {
      console.error("[RAG] üí• Error in RAG pipeline:", err);
      return [];
    }
  }

  /**
   * Enhance query for better Vietnamese administrative term matching
   */
  private enhanceQueryForVietnameseTerms(query: string): string {
    // Common Vietnamese administrative term mappings
    const termMappings: { [key: string]: string[] } = {
      't·∫°m tr√∫': ['t·∫°m tr√∫', 'ƒëƒÉng k√Ω t·∫°m tr√∫', 'KT3', 'khai b√°o t·∫°m tr√∫', 'th·ªß t·ª•c t·∫°m tr√∫'],
      't·∫°m v·∫Øng': ['t·∫°m v·∫Øng', 'ƒëƒÉng k√Ω t·∫°m v·∫Øng', 'gi·∫•y t·∫°m v·∫Øng', 'khai b√°o t·∫°m v·∫Øng'],
      'th∆∞·ªùng tr√∫': ['th∆∞·ªùng tr√∫', 'ƒëƒÉng k√Ω th∆∞·ªùng tr√∫', 'h·ªô kh·∫©u', 's·ªï h·ªô kh·∫©u', 'KT2'],
      'khai sinh': ['khai sinh', 'gi·∫•y khai sinh', 'ƒëƒÉng k√Ω khai sinh'],
      'khai t·ª≠': ['khai t·ª≠', 'gi·∫•y khai t·ª≠', 'ƒëƒÉng k√Ω khai t·ª≠'],
      'ƒëƒÉng k√Ω k·∫øt h√¥n': ['k·∫øt h√¥n', 'ƒëƒÉng k√Ω k·∫øt h√¥n', 'gi·∫•y ch·ª©ng nh·∫≠n k·∫øt h√¥n'],
      'ly h√¥n': ['ly h√¥n', 'gi·∫£i quy·∫øt ly h√¥n', 'th·ªß t·ª•c ly h√¥n'],
      'c·∫•p gi·∫•y ph√©p': ['gi·∫•y ph√©p', 'c·∫•p ph√©p', 'gi·∫•y ph√©p x√¢y d·ª±ng', 'gi·∫•y ph√©p kinh doanh'],
      'h√†nh ch√≠nh': ['h√†nh ch√≠nh', 'th·ªß t·ª•c h√†nh ch√≠nh', 'd·ªãch v·ª• c√¥ng', 'c·ªïng d·ªãch v·ª• c√¥ng'],
      'gi·∫•y t·ªù': ['gi·∫•y t·ªù', 'h·ªì s∆°', 'th·ªß t·ª•c', 'gi·∫•y ph√©p'],
      'l·ªá ph√≠': ['l·ªá ph√≠', 'ph√≠', 'ti·ªÅn l·ªá ph√≠', 'thu ph√≠'],
      'th·ªùi gian': ['th·ªùi gian', 'th·ªùi h·∫°n', 'th·ªß t·ª•c', 'gi·∫£i quy·∫øt'],
      'n∆°i c∆∞ tr√∫': ['n∆°i c∆∞ tr√∫', 'ƒë·ªãa ch·ªâ', 'ch·ªó ·ªü', 'h·ªô kh·∫©u'],
      'ch·ª©ng minh': ['ch·ª©ng minh', 'x√°c nh·∫≠n', 'x√°c th·ª±c', 'ch·ª©ng th·ª±c'],
      '·ªßy quy·ªÅn': ['·ªßy quy·ªÅn', '·ªßy nhi·ªám', '·ªßy th√°c', 'gi·∫•y ·ªßy quy·ªÅn'],
      'x√°c nh·∫≠n': ['x√°c nh·∫≠n', 'x√°c th·ª±c', 'ch·ª©ng th·ª±c', 'x√°c minh'],
    };

    let enhancedQuery = query.toLowerCase();

    // Expand query with related terms
    for (const [mainTerm, relatedTerms] of Object.entries(termMappings)) {
      if (enhancedQuery.includes(mainTerm)) {
        // Add related terms to the query for better matching
        relatedTerms.forEach(term => {
          if (!enhancedQuery.includes(term)) {
            enhancedQuery += ` ${term}`;
          }
        });
      }
    }

    return enhancedQuery;
  }

  /** Vector search */
  private async searchByVector(query: string, topK: number) {
    console.log(`[RAG] üßÆ Vector search...`);
    const embedding = await this.generateEmbedding(query);
    if (!embedding) return [];

    try {
      const results = await searchByVector(embedding, topK);
      return results.map((r) => ({
        ...r,
        source: "vector" as const,
      }));
    } catch (err) {
      console.error("[RAG] ‚ùå Vector search failed:", err);
      return [];
    }
  }

  /** Keyword search */
  private async searchByKeywords(query: string, topK: number) {
    console.log(`[RAG] üîë Keyword search...`);
    try {
      const results = await searchByKeywords(query, topK);
      return results.map((r) => ({
        ...r,
        source: "keyword" as const,
      }));
    } catch (err) {
      console.error("[RAG] ‚ùå Keyword search failed:", err);
      return [];
    }
  }

  /** Merge + Rank results */
  private mergeAndRank(
    vectorResults: KnowledgeChunk[],
    keywordResults: KnowledgeChunk[],
    topK: number,
  ): KnowledgeChunk[] {
    const merged: KnowledgeChunk[] = [];
    const seen = new Set<string>();

    const allItems = [...vectorResults, ...keywordResults];
    for (const item of allItems) {
      if (seen.has(item.id)) continue;
      seen.add(item.id);

      const score =
        (item.source === "vector" ? this.vectorWeight : 0) * item.similarity +
        (item.source === "keyword" ? this.keywordWeight : 0) * item.similarity;

      // Only add items that meet the minimum similarity threshold
      if (score >= this.minSimilarity) {
        merged.push({
          ...item,
          similarity: score,
          source: "hybrid",
          content: this.cleanText(item.content),
        });
      }
    }

    return merged.sort((a, b) => b.similarity - a.similarity).slice(0, topK);
  }

  /** Generate embedding */
  private async generateEmbedding(text: string): Promise<number[] | null> {
    const cacheKey = embeddingCache.getCacheKey("embedding", {
      text: text.substring(0, 200),
    });
    const cached = embeddingCache.get<number[]>(cacheKey);
    if (cached) return cached;

    try {
      const roles = await getAiRoles();
      const ragModelId = roles.rag;
      const models = await getModels();
      const embeddingModel = models.find((m) => m.id === ragModelId);

      let modelName = "BAAI/bge-small-en-v1.5";
      if (
        embeddingModel?.model_string &&
        embeddingModel.model_string.includes("bge")
      ) {
        modelName = embeddingModel.model_string;
      }

      const response = await this.hfClient.featureExtraction({
        model: modelName,
        inputs: text,
      });

      const emb = Array.isArray(response[0]) ? response[0] : response;
      const embedding = emb as number[];

      embeddingCache.set(cacheKey, embedding);
      return embedding;
    } catch (err) {
      console.error("[RAG] ‚ùå Embedding generation failed:", err);
      return null;
    }
  }

  /** Clean text (remove HTML, normalize spaces) */
  private cleanText(text: string): string {
    return text
      .replace(/<\/?[^>]+(>|$)/g, "")
      .replace(/\s+/g, " ")
      .trim();
  }

  formatContext(chunks: KnowledgeChunk[]): string {
    if (chunks.length === 0) return "";
    return chunks
      .map((chunk, index) => {
        const sourceUrl =
          chunk.metadata?.content_url || chunk.metadata?.source || "";
        const sourceInfo = sourceUrl ? `\nNgu·ªìn: ${sourceUrl}` : "";
        return `[Ki·∫øn th·ª©c ${index + 1}]:\n${chunk.content}${sourceInfo}\n`;
      })
      .join("\n");
  }
}
